{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAFD2_Xtreme_Random_Trees.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdIqLLHvm-eG"
      },
      "source": [
        "#Statistical Analysis of Financial Data - Project Part 2: **Extremely Randomized Forests**\n",
        "# Kushagra Mahajan (170123029)<br> Mihir Yadav (170123034)\n",
        "###Group 3\n",
        "#Disclaimer\n",
        "*The content of this report and the product made is only meant for learning process as part of the course. This is not for use of making publication or making commercialisation without mentor’s consent. My contribution won’t demand any claim in future for further progress of Mentor’s development and innovation along the direction unless there is a special continuous involvement.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwfgMcOBw3qA"
      },
      "source": [
        "#Extremely Randomized/Extra Trees Algorithm\n",
        "As part of the project 1 we worked on constructing a decision tree algorithm and then created classical random forests, by introducing variation in the decision trees.\n",
        "\n",
        "We used bootstrapping and and the generic technique of random-subspace projection, which is choosing a random subset of attributes for each tree, to build random decision trees for a forest.\n",
        "\n",
        "Although these significantly randomized the standard tree growing algorithm, they are far from building totally random trees. The very high variance of decision/regression tree splits motivated the use of even higher randomization levels, that could give better performance, both in terms of accuracy and computational efficiency.  \n",
        "\n",
        "For this purpose we look at another tree-ensemble technique which aims at strongly randomizing the individual decision trees. The strength of this randomization can be controlled by the use of a parameter. In extreme cases, totally random trees can be built, with structures independent of the output values of the training samples.\n",
        "\n",
        "##Algorithm description\n",
        "The Extra-trees algorithm builds an ensemble of unpruned decision trees with increased randomization with respect to the trees constructed as part of Project 1. The classical top-down approach is used for construction.\n",
        "\n",
        "To increase the randomization level, at each tree node, a random subset of features is chosen to be split on, and further the cut-point for each split is chosen at random. The split that gives maximum variance reduction at the node is chosen. In the extreme case only one feature is chosen at random and the samples are split at a random cut-point for this feature. This way *Totally Randomized Tress* are built, without taking the target variable of the training samples into account. We introduce a parameter *subset_size_factor* that can control the extent of randomization in trees.\n",
        "\n",
        "This algorithm differs from the previous implementation also with respect to the treatment of training samples. The whole training data available is used instead of a bootstrap replica as in the previous implementation.\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "####**Extra-trees splitting algorithm for numerical attributes**\n",
        "---\n",
        "**Split node** (S):<br>\n",
        "  *Input:* The training subset at a tree node with attributes [$a_{1}, a_{2}, a_{3}\\cdots, a_{n}$].<br>\n",
        "  *Output:* A split at this node in the form of *(feature, cut-point)*<br>\n",
        "\n",
        "\n",
        "\n",
        "*   $k$ = subset_size_factor*$n$\n",
        "<br>\n",
        "*   Randomly select $k$ features $[a_{p_{1}},a_{p_{2}}, a_{p_{3}}\\cdots,a_{p_{k}}]$\n",
        "<br>\n",
        "*   Randomly select cut-points $s_{p_{i}}$ for each feature $a_{p_{i}}$ as $s_{p_{i}} = random(minS(a_{p_{i}}), maxS(a_{p_{i}}))$ \n",
        "<br>\n",
        "*   Select the split feature and cut-point as $(a_{p}, s_{p})$ which gives the maximum variance reduction, that is $VarReduction(S, a_{p}, s_{p}) = \\displaystyle\\max_{i=1}^{k}{VarReduction(S, a_{p_{i}}, s_{p_{i}})}$\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "<br>\n",
        "The tree is built and nodes split until some stopping criterion is met. For this project we use the $\\mathrm{coefficient\\ of\\ variance}$: \n",
        "<br>\n",
        "$\\mathrm{CoefVar} = \\dfrac{\\mathrm{Standard\\ Deviation}}{\\mathrm{Mean}} = \\dfrac{\\sqrt{\\dfrac{1}{n}\\sum_{j}(y_{j}-\\bar y)^{2}}}{\\bar y}$\n",
        "\n",
        "which is a measure of the variability of data relative to the mean.\n",
        "\n",
        "At every node we calculate this coefficient and if it falls below a certain threshold, $i.e.$ the variability of data has reduced enough, the node is not split any more.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV65TamQPGZY"
      },
      "source": [
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "class TreeNode:\n",
        "    def __init__(self):\n",
        "        self.predicted_value = None\n",
        "        self.decision_feature = None\n",
        "        self.decision_value = None\n",
        "        self.left_node = None\n",
        "        self.right_node = None\n",
        "\n",
        "\n",
        "class DecisionTree:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.root_node = None\n",
        "        self.min_coef_of_var = None\n",
        "        self.subset_size_factor = None\n",
        "        self.reductions = None\n",
        "\n",
        "    def fit(self, X, Y, min_coef_of_var = 0, pruning_factor = 0, subset_size_factor = 1/np.sqrt(len(X_train[0])), extremely_randomized=False):\n",
        "        self.min_coef_of_var = min_coef_of_var\n",
        "        self.subset_size_factor = subset_size_factor\n",
        "        self.extremely_randomized = extremely_randomized  #Prameter that controls whether to create extremely randomized trees.\n",
        "        self.root_node = self.build(X, Y)\n",
        "        self.prune_decision_tree(X, Y, self.root_node, pruning_factor)\n",
        "\n",
        "        self.reductions = np.zeros(len(X[0]))\n",
        "        self.reductions = self.calculate_reductions(X, Y, self.root_node, self.reductions)\n",
        "\n",
        "    def get_decision_value_for_feature(self, X, Y, decision_feature):\n",
        "        \n",
        "        Z = np.empty((0, 2), float)\n",
        "        for i in range(len(Y)):\n",
        "            Z = np.append(Z, [[X[i, decision_feature], Y[i]]], axis = 0)\n",
        "\n",
        "        Z = np.sort(Z, axis = 0)\n",
        "\n",
        "        left_cardinality = 0\n",
        "        right_cardinality = 0\n",
        "        left_sum = 0\n",
        "        right_sum = 0\n",
        "        left_sum_of_squares = 0\n",
        "        right_sum_of_squares = 0\n",
        "\n",
        "        for i in range(len(Z)):\n",
        "            right_cardinality += 1\n",
        "            right_sum += Z[i, 1]\n",
        "            right_sum_of_squares += Z[i, 1] ** 2\n",
        "\n",
        "        current_best_impurity = right_sum_of_squares\n",
        "        current_best_decision_value = Z[0, 0] - 1\n",
        "\n",
        "        for i in range(len(Z)):\n",
        "            left_cardinality += 1\n",
        "            left_sum += Z[i, 1]\n",
        "            left_sum_of_squares += Z[i, 1] ** 2\n",
        "\n",
        "            right_cardinality -= 1\n",
        "            right_sum -= Z[i, 1]\n",
        "            right_sum_of_squares -= Z[i, 1] ** 2\n",
        "\n",
        "            impurity = left_sum_of_squares - left_sum * left_sum / left_cardinality\n",
        "            if (right_cardinality != 0):\n",
        "                impurity += right_sum_of_squares - right_sum * right_sum / right_cardinality\n",
        "            \n",
        "            if (impurity < current_best_impurity):\n",
        "                current_best_impurity = impurity\n",
        "                current_best_decision_value = Z[i, 0]\n",
        "\n",
        "        return current_best_decision_value\n",
        "\n",
        "    def get_impurity(self, X, Y, decision_feature, decision_value_for_feature):\n",
        "        left_cardinality = 0\n",
        "        right_cardinality = 0\n",
        "        left_sum = 0\n",
        "        right_sum = 0\n",
        "\n",
        "        for i in range(len(Y)):\n",
        "            if (X[i, decision_feature] <= decision_value_for_feature):\n",
        "                left_cardinality += 1\n",
        "                left_sum += Y[i]\n",
        "            else:\n",
        "                right_cardinality += 1\n",
        "                right_sum += Y[i]\n",
        "\n",
        "        if (left_cardinality != 0):\n",
        "            left_mean = left_sum / left_cardinality\n",
        "        else:\n",
        "            left_mean = 0\n",
        "\n",
        "        if (right_cardinality != 0):\n",
        "            right_mean = right_sum / right_cardinality\n",
        "        else:\n",
        "            right_mean = 0\n",
        "\n",
        "        impurity = 0\n",
        "        for i in range(len(Y)):\n",
        "            if (X[i, decision_feature] <= decision_value_for_feature):\n",
        "                impurity += (Y[i] - left_mean) ** 2\n",
        "            else:\n",
        "                impurity += (Y[i] - right_mean) ** 2\n",
        "\n",
        "        return impurity\n",
        "\n",
        "    def divide_data(self, X, Y, decision_feature, decision_value):\n",
        "        number_of_features = len(X[0])\n",
        "        X_left = np.empty((0, number_of_features), float)\n",
        "        X_right = np.empty((0, number_of_features), float)\n",
        "        Y_left = np.empty(0, float)\n",
        "        Y_right = np.empty(0, float)\n",
        "\n",
        "        for i in range(len(X)):\n",
        "            if (X[i, decision_feature] <= decision_value):\n",
        "                X_left = np.append(X_left, [X[i]], axis = 0)\n",
        "                Y_left = np.append(Y_left, [Y[i]], axis = 0)\n",
        "            else:\n",
        "                X_right = np.append(X_right, [X[i]], axis = 0)\n",
        "                Y_right = np.append(Y_right, [Y[i]], axis = 0)\n",
        "\n",
        "        return X_left, Y_left, X_right, Y_right\n",
        "\n",
        "    def build(self, X, Y):\n",
        "        if (len(X) == 0):\n",
        "            return\n",
        "\n",
        "        root_node = TreeNode()\n",
        "        node_mean = np.mean(Y)\n",
        "        root_node.predicted_value = node_mean\n",
        "        node_deviation = np.std(Y)\n",
        "\n",
        "        # Do not split\n",
        "        if (node_deviation / node_mean < self.min_coef_of_var):\n",
        "            root_node.decision_value = 0\n",
        "            root_node.decision_feature = 0\n",
        "            return\n",
        "\n",
        "        if (np.amin(Y) == np.amax(Y)):\n",
        "            root_node.decision_value = 0\n",
        "            root_node.decision_feature = 0\n",
        "            return root_node\n",
        "\n",
        "        \n",
        "        current_best_feature = -1\n",
        "        current_best_decision_value = -1\n",
        "        current_best_impurity = -1\n",
        "        number_of_features = len(X[0])\n",
        "        if self.extremely_randomized == True:\n",
        "          features_subset = random.sample(range(number_of_features),int(number_of_features*self.subset_size_factor))\n",
        "        else:\n",
        "          features_subset = range(number_of_features)\n",
        "        ## iterate only on a subset of features and choose the best among them\n",
        "        for i in features_subset:\n",
        "            if self.extremely_randomized == False:\n",
        "              decision_value_for_feature = self.get_decision_value_for_feature(X, Y, i)\n",
        "            else:\n",
        "              decision_value_for_feature = random.sample(list(X[:, i]),1) ## pick a random cut point\n",
        "            impurity_of_decision_value = self.get_impurity(X, Y, i, decision_value_for_feature)\n",
        "\n",
        "            if (current_best_feature == -1 or impurity_of_decision_value < current_best_impurity):\n",
        "                current_best_feature = i\n",
        "                current_best_decision_value = decision_value_for_feature\n",
        "                current_best_impurity = impurity_of_decision_value\n",
        "\n",
        "        root_node.decision_feature = current_best_feature\n",
        "        root_node.decision_value = current_best_decision_value\n",
        "\n",
        "        X_left, Y_left, X_right, Y_right = self.divide_data(X, Y, root_node.decision_feature, root_node.decision_value)\n",
        "\n",
        "        if (len(Y_left) == 0 or len(Y_right) == 0):\n",
        "            return root_node\n",
        "        root_node.left_node = self.build(X_left, Y_left)\n",
        "        root_node.right_node = self.build(X_right, Y_right)\n",
        "        return root_node\n",
        "\n",
        "    def prune_decision_tree(self, X, Y, root_node, pruning_factor):\n",
        "        if (root_node == None):\n",
        "          return 0\n",
        "\n",
        "        X_left, Y_left, X_right, Y_right = self.divide_data(X, Y, root_node.decision_feature, root_node.decision_value)\n",
        "        left_tree_size = self.prune_decision_tree(X_left, Y_left, root_node.left_node, pruning_factor)\n",
        "        right_tree_size = self.prune_decision_tree(X_right, Y_right, root_node.right_node, pruning_factor)\n",
        "        tree_size = 1 + left_tree_size + right_tree_size\n",
        "\n",
        "        impurity = 0\n",
        "        for y in Y:\n",
        "            impurity += (y - root_node.predicted_value) ** 2\n",
        "\n",
        "        divided_impurity = self.get_impurity(X, Y, root_node.decision_feature, root_node.decision_value)\n",
        "\n",
        "        pruning_value = impurity / len(Y) - divided_impurity / len(Y) - pruning_factor * tree_size\n",
        "\n",
        "        if (pruning_value < 0):\n",
        "            root_node.left_node = None\n",
        "            root_node.right_node = None\n",
        "            return 1\n",
        "        else:\n",
        "            return tree_size\n",
        "    \n",
        "    def calculate_reductions(self, X, Y, root_node, reductions):\n",
        "        if (root_node == None):\n",
        "            return reductions\n",
        "\n",
        "        impurity = 0\n",
        "        for y in Y:\n",
        "            impurity += (y - root_node.predicted_value) ** 2\n",
        "\n",
        "        for i in range(len(X[0])):\n",
        "            decision_value_for_feature = self.get_decision_value_for_feature(X, Y, i)\n",
        "            impurity_of_decision_value = self.get_impurity(X, Y, i, decision_value_for_feature)\n",
        "\n",
        "            reductions[i] += impurity - impurity_of_decision_value\n",
        "        \n",
        "        X_left, Y_left, X_right, Y_right = self.divide_data(X, Y, root_node.decision_feature, root_node.decision_value)\n",
        "        reductions = self.calculate_reductions(X_left, Y_left, root_node.left_node, reductions)\n",
        "        reductions = self.calculate_reductions(X_right, Y_right, root_node.right_node, reductions)\n",
        "\n",
        "        return reductions\n",
        "    \n",
        "    def get_reductions(self):\n",
        "        return self.reductions\n",
        "\n",
        "    def predict_single(self, X):\n",
        "        current_node = self.root_node\n",
        "        while (True):\n",
        "            if (X[current_node.decision_feature] <= current_node.decision_value):\n",
        "                if (current_node.left_node != None):\n",
        "                    current_node = current_node.left_node\n",
        "                else:\n",
        "                    return current_node.predicted_value\n",
        "            else:\n",
        "                if (current_node.right_node != None):\n",
        "                    current_node = current_node.right_node\n",
        "                else:\n",
        "                    return current_node.predicted_value\n",
        "\n",
        "    def predict(self, X):\n",
        "        Y = np.empty(0, float)\n",
        "        for x in X:\n",
        "            Y = np.append(Y, [self.predict_single(x)], axis = 0)\n",
        "\n",
        "        return Y\n",
        "\n",
        "decision_tree = DecisionTree()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJnQKidglmyF"
      },
      "source": [
        "We will use Boston housing data from ```sklearn.datasets``` for testing our algorithm.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z63Hg3prQLZS"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "data = load_boston(return_X_y=False)\n",
        "X = data.data\n",
        "y = data.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB_S17NXmJco"
      },
      "source": [
        "We fit our decision tree to the training data, and check our performance on the test data.\n",
        "\n",
        "**Note:** Using a single Extra-tree does not make sense because the tree structure is based on random splits, hence we need to make an **ensemble of multiple Extra-trees** as shown later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF9wssGhQTBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a6ecfe-64e9-49c5-ea0f-7d5467b20011"
      },
      "source": [
        "import random\n",
        "decision_tree.fit(X_train, y_train, min_coef_of_var = 0.025, pruning_factor = 0, extremely_randomized=True)\n",
        "y_test_pred = decision_tree.predict(X_test)\n",
        "metrics.r2_score(y_test, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5389992736916642"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AWbvbVTWBac"
      },
      "source": [
        "For a single tree with randomized splits, as expected the fit is not good"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Tmpwy6yVVwNk",
        "outputId": "31ad4a4a-8e29-4594-c4ce-f34441189256"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(y_test, y_test, color = \"green\")\n",
        "plt.xlabel(\"actual\")\n",
        "plt.ylabel(\"predicted\")\n",
        "plt.scatter(y_test, y_test_pred)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df5gcVZ3v8fc3kyEZCDIgkYWBZFBZIookMquRoPJjFbhESJAHYdHl+nAXXd2rggbDrmvILruEiwt4V69eHn+FVSBcDUMIAmICy64K7oRJFhGiizCYIZBgGCCmSWYm3/tHVw/9u2tmuqq6uz6v58kzXaeru87Uk/nWqXNOfY+5OyIikh5Tkq6AiIjES4FfRCRlFPhFRFJGgV9EJGUU+EVEUmZq0hUI4+CDD/bu7u6kqyEi0lQ2bNjwgrvPLC5visDf3d1NX19f0tUQEWkqZjZQrlxdPSIiKaPALyKSMgr8IiIpo8AvIpIyCvwiIikT6aweM3saeAUYBUbcvcfMDgJWAd3A08B57v5ilPUQEZHXxNHiP9nd57p7T7C9FFjn7kcB64JtERGJSRJdPWcDK4PXK4FFCdRBRKSh2XLDlhtRpM6POvA78GMz22BmlwRlh7j71uD1c8Ah5T5oZpeYWZ+Z9W3fvj3iaoqINIahV4ew5Ta2/cDTD9T9GFE/uXuiuw+a2RuA+8zsifw33d3NrOzlzN1vBG4E6Onp0WoxItLy8gN+zslHnlz340Qa+N19MPi5zcxuB94JPG9mh7r7VjM7FNgWZR1ERBrd5hc2M+drcwrK9nxxD+1t7ZEcL7KuHjPbz8z2z70GPgD8ElgDXBTsdhFwR1R1EBFpdLbcCoJ+5/ROfJlHFvQh2hb/IcDtZpY7zs3ufo+Z/Qdwm5ldDAwA50VYBxGRhnTXr+9i4S0LC8p8WTy92pEFfnf/LXBcmfLfA6dGdVwRkUZX3Je/eM5iVn94dWzHb4q0zCIireCaf7+GpesKH12Kq5WfT4FfRCQGxa38Faeu4AsnfiGRuijwi4hEaO435rLp+U0FZUm08vMp8ItIy+ntH+Taezfz7FCGwzo7WHLa0Sya1xV7PYpb+bd86BbOf9v5sdejmAK/iLSU3v5Brlj9KJnhUQAGhzJcsfpRgNiCf7kHsZJu5edTWmYRaSnX3rt5LOjnZIZHufbezZEfe8/onpKg3//x/oYK+qAWv4i0mGeHMuMqr5dGb+XnU4tfRFrKYZ0d4yqfrOd2PlcS9Lcv2d6wQR8U+EWkxSw57Wg62tsKyjra21hy2tF1P5YtNw79p0MLynyZc/C+B9f9WPWkrh4RaSm5AdwoZ/U8vOVh5n9rfkHZ8N8OM3VKc4TU5qiliMg4LJrXFdkMnmbqy69EXT0iIiF8u//bJUHfl3nTBX1Qi19EpKbigP+eWe/hwY89mFBtJk+BX0Skgo/f+XFufOTGgrJmbOEXU+AXESmjuJX/pfd+ieUnL0+oNvWlwC8ikqf7hm4GXhooKGuFVn4+BX4REcDdmfJ3hfNdej/cy9lzzk6oRtFR4BeR1GuFKZrjocAvIqm1a3gX+/3jfgVlv/rkr3jLzLckVKN4KPCLSCqlrZWfT4FfRFLlyR1P8uZ/fnNB2e8v/z0HdRyUUI3ip8AvIqmR5lZ+PgV+EWl5P/rNjzjz5jMLykb+doS2KW0VPtHaFPhFpKWplV9KSdpEpCV99p7PtkxStXpTi19EWk5xwH/7IW9n0yc2JVSbxqPALy2tt38w0gU5pLHMvmE2z7z0TEGZWvil1NUjLau3f5ArVj/K4FAGBwaHMlyx+lF6+weTrppEwJZbQdD/2NyPKehXoBa/tKxr791MZni0oCwzPMq1925Wq7+FaPB2/NTil5b17FBmXOXSXPb63pKgv3LRSgX9ENTil5Z1WGcHg2WC/GGdHQnURuqp1Vv5UY9NqcUvLWvJaUfT0V74gE5HextLTjs6oRrJZO3I7CgJ+ps+sanlgn7UY1Nq8UvLyrWQNKunNbR6Kz8njrEpBX5paYvmdSnQN7lfDP6Cd33zXQVlOy7fwYEdByZUo2jFMTalwC8iDSstrfx8cYxNqY9fRBrOV3/x1ZKgP/ql0ZYP+hDP2FTkLX4zawP6gEF3X2hmRwK3Aq8HNgAfdfc9UddDRJpDGlv5+eIYm4qjq+czwOPA64Lta4Dr3f1WM/sGcDHw9RjqISIN7Mybz+RHv/lRQVmaAn6+qMemIu3qMbPDgTOBbwbbBpwC/CDYZSWwKMo6iEjjs+VWEPSntU1LbdCPQ9Qt/huAy4H9g+3XA0PuPhJsbwHKXtbM7BLgEoBZs2ZFXE0RSULau3WSElmL38wWAtvcfcNEPu/uN7p7j7v3zJw5s861E5GkFQf9Pz/uzxX0YxJli38BcJaZ/TdgOtk+/q8AnWY2NWj1Hw4oVaJIiqiVn7zIWvzufoW7H+7u3cD5wHp3vxC4Hzg32O0i4I6o6iAijWNk70hJ0L9p0U0K+glI4gGuLwC3mtlVQD/wrQTqICIxqmcrP4oEZnEs2DOeY0Rdn1gCv7s/ADwQvP4t8M44jisiyXpu53Mc+k+HFpQ99snHOGbmMRP6vlwCs1wum1wCM2DCgTGK75zMMeKoj57cFZFI2HIrCfq+zCcc9KF6ArNG+s7JHCOO+ihXj4jU1YMDD/K+776voOyVK15hxj4zJv3dUSQwiyMp2niOoSRtItJUop6xE0UCsziSoo3nGErSJiJN4ep/u7ok6O/90t66z9iJIoFZHEnRxnOMlkjSJiKtLc55+VEkMIsjKdp4jhFHfcy98efQ9vT0eF9fX9LVEJE8J3zrBH6+5ecFZZqT31jMbIO79xSXq8UvIuNW3Mrv2r+LLZdtSag2Ml4K/CISmtIttAYN7opIKEqq1jrU4heRqsq18k+Yto4HH8qw4In1kaQ3kGipxS8iZe0e2V0S9C97x1eZM3I3g0MZnNfSCfT2K8luM1HgF5ESttyY/g/TC8p8mfPQY2+JPJ2ARE+BX0TG/Ob3vylp5T/xqSfG+vLjSCcg0VMfv4gA4WbsVEoncEBHe2T1kvpTi18k5W5+9OaSoP+Hv/5D2Rk7S047mvYppReIP+wZUT9/E1HgF0kxW25cuPrCgjJf5uzbvm/Z/RfN62LG9NKOguFRVz9/E1FXj0gKnX3r2azZvKagLOyc/KFdw2XL1c/fPBT4RVJmsk/fxpE2WKKlwC+SEvVKt7DktKMLlgaE+qcNlmgp8IuMQxyLckehnjl24kgbLNFS4BcJKY5FsOstqqRqi+Z1NezvLLVpVo9ISHEsgl1PxUF/8ZzFSqomgFr8IqE1y1OrSp0stajFLxJSpVkrjTKbZeeenSVB/6ZFNynoSwm1+KWumnXwM4xGns2iVr6MhwK/1E0zDn6ORyPOZunf2s87bnxHQdmv/+rXHPX6oxKqkTQDBX6pm2qDn60Q+KGxZrOold+6or5zVh+/1E2zDH42u+t/fn1J0H/1b15V0G8RuTvnKBe7qdriN7PLqr3v7tfVrSbS9OJ8lL8VxxLC/E5q5be+OO6ca3X17B/8PBr4EyCX1emDwC/qUgNpGXENfrbiWEKt32n+N+fz8ODDBZ+JMuC34oW1WcRx51w18Lv7cgAzexB4h7u/EmxfCdxVt1pIS4hr8LMVxxKq/U6L1xxesn/UQb/VLqzNJI4757CDu4cAe/K29wRlIgXiGPxsxbGEcnUf6FjIwO7Csji6dVrxwtpM4rhzDhv4bwJ+YWa3B9uLgJV1q4XIOLRiWuDi32mgY2HJPnH15bfihbWZxHHnHCrwu/s/mNndwHuCoo+5e3/daiEyDo38INVE5X6nJ6aeUfJe3IO3rXhhbTZR3zmPZzrnvsDL7v4VYIuZHRlRnUSqWjSvi6vPOZauzg4M6Ors4Opzjm3qboiz5x5WEvT/dNYFiczYWXLa0XS0txWUNfuFVQqFavGb2TKgh+zsnu8A7cD3gAXRVU3SrtrMkkZ6kGqyGm2KZiM+oSz1FbaPfzEwD3gEwN2fNbP9q39EZOLSMLPkhV0vMPPamQVlq85dxXlvPS+hGr2mlS6sUips4N/j7m5mDmBm+9X6gJlNBx4EpgXH+YG7Lwu6iG4FXg9sAD7q7nsqf5OkUavPLGm0Vr6kS9g+/tvM7P8CnWb2F8BPgG/W+Mxu4BR3Pw6YC5xuZvOBa4Dr3f3NwIvAxROrurSyZphZ0ts/yIIV6zly6V0sWLE+1CP19/zXPSVB/6nPPKWgL7EKO6vny2b2fuBlsv38X3L3+2p8xoGdwWZ78M+BU4A/C8pXAlcCXx93zaWlNfrMkol0RamVL40iVIvfzK5x9/vcfYm7f97d7zOza0J8rs3MNgLbgPuAJ4Ehdx8JdtkClP0rMbNLzKzPzPq2b98e7reRltHoM0vGswzjRb0XlQT92Zk7OGHaurom3hIJK2wf//uBLxSVnVGmrIC7jwJzzawTuB2YE7Zi7n4jcCNAT0+PmkUVtGpOlUafWRK2K6pcK392Zi3QmgPW0hxqZef8S+CTwJvM7D/z3tof+FnYg7j7kJndD7yb7DjB1KDVfzigJs8EtfrMl0aeWVKrK6pcwD9h2rqSz7TSgLU0j1pdPTeTzcR5R/Az9+94d7+w2gfNbGbQ0sfMOsjeNTwO3A+cG+x2UfDdMgHj6W6Q+qrWFVWpL78ZBqwlHWpl53wJeMnMvgLsyMvO+Toze5e7P1zl44cCK82sjewF5jZ3X2tmvwJuNbOrgH7gW3X5TVJIgSQ55bqifrb7VBavKdwvf/C20QesJT3C9vF/Hchf2HNnmbIC7v6fZB/6Ki7/LfDOcdRRKlAgSVZ+V1SYGTutmGNImlPYwG/B9EwA3H2vmWm93oQpkCRvPFM0G33AWtIjbPD+rZl9mtfm238S+G00VZKwFEiSM7p3lKl/X/jnc/qbT+fuC++u+rlGHrCW9Agb+D8B/G/gi2QfwloHXBJVpSQ8BZL46UEsaXZhn9zdBpwfcV1EGtrmFzYz52uFj6L8y+J/4SNv/0hCNRKZmFrz+C939/9lZv9MtqVfwN0/HVnNRBqIWvnSSmq1+B8PfvZFXRGRRnT9z6/nsh9fVlD21GeeoruzO5kKidRBrXn8dwY/tb5ugpJMyxDHsXPHGBzK0GbGqDtdRcdK4hyolS+tqlZXz52U6eLJcfez6l4jKZBkWoY4jl18jNFg1nD+sYBYz0H3Dd0MvDRQUDb6pVGm2HhWKhVpXLW6er4c/DwH+COyyy0CXAA8H1Wl5DVJLkgSx7HLHaP4WLnXUdYjJw2t/FZN7Cfh1erq+VcAM/snd+/Je+tOM1O/fwySTMsQx7FrfVe19/Pfm2wwm2zAb5Zg2uqJ/SScsPeu+5nZG3MbwfKJNZdflMmrlH4hjrQMcRy71ncd1tlRsx65YDY4lMF5LZiFzXVfj6A/mePHSYn9BMIH/kuBB8zsATP7V7IZNj8bXbUkJ8kFSeI4drljFB+rVj0mGsxsuZUEfV/m4+7aaaZgqsR+AuEf4LrHzI7itYVUnnD33dFVS3KSTMsQx7Hzj1FuVk/fwA5uefh3Y4O+QMmMn4kEs3Kt/NvP2sKCFevH/bs2UzBVYj+BkIHfzPYFLgNmu/tfmNlRZna0u6+NtnoCyaZliOPYlY7xxd5H+d5Dz5SUnzxnZsH+4wlmlbp1JtP33UzBVIn9BMJ39XwH2EN2BS3Irpp1VSQ1Egnc8vDvapb39g+ya89IyT7FwezVkVdLgv57Zr1nrFtnMt01jb4+cL5F87q4+pxj6erswMjePV19zrEa2E2ZsEna3uTuHzazCwDcfZeZlTadROogN0Mmv3snX668uJWe09nRzpVnvXVcufIn013TbFlSldhPwgb+PcHyiQ5gZm8C1McvddXbP8iVax5jKDNcdb+2oM1R6RmA/aZNZdG8Ln76zE858TsnFrx38zk3c8GxF5R8ZrLdNQqm0kzCBv5lwD3AEWb2fWAB8N+jqpSkT6XWezkXvOsIoHorfbxTNNX3LWlSM/Cb2RTgQLJP784HDPiMu78Qcd0kRao9wZvTZsYF7zqCqxYdC5RvpW9vX8Guqf9eULbl0i10va56a7zZumtEJqNm4A+WWbzc3W8D7oqhTpJCtfrSOzva2bjsAwVlS047miU/2MTwaLYlP9CxsORz45mTr+4aSYuws3p+YmafN7MjzOyg3L9IayapUqsvfc/IKAtWrOfIpXexYMV6evsHWTSvi/32mcpAx8KSoP/ufX7Scjl2ROolbB//h8kO7H6yqPyNZfYVGbdyfez5dg3vZVdwV5A/x34Tp5XsOzuzlq2ZV6OrrEiTCxv4jyEb9E8kewH4N+AbUVVK0ifXxfK52zZVnMaZ74mpZ7B4TWHZ7MxrzxM24sNTIo0ibOBfCbxMdsF1gD8Lys6LolLSXOqVmTL3mVqze8r15ecHfc3GEakubOB/m7sfk7d9v5n9KooKSXOpV5rf/ItH577tgJMZ3gvAFIO9XnnwtllSIouE9cXeR8dyVBXPZquHsIH/ETOb7+4PAZjZu9A6vJGLKqDV83vDLtZS7ZjFF48XdxU+wFUp6N9+1hZAs3GktRTnqBp1H9uuV/APG/iPB35mZrnazAI2m9mjgLv72+tSGxkT1YIZ9f7eMKkOah2z2hz+cgH/hGnrxrpyJpJNU6SRVctRVa/AH3Y65+nAkcD7gn9HBmULgQ/WpSZSIKoc7/X+3jCLtdQ6ZrmLxygvlQT9KT4DX+b8dOkpACWLn1y6aiNf7H205LtEmkmtHFX1ECrwu/tAtX91q42MiSrHe72/N0xmylrHLL54DHQsZEvHhQVlszNr6d69amxVq3IXEwe+99AzzF3+44Zc/UokjLYK+S8rlU9E2Ba/xCyqZQ/r/b1h0vzWOmbu4vFy250lrfyD9nxybMbOqPvYkobVLlRDmeGGW/qwt3+w5AE0kXJyuajClk+EeR1vH6LS09PjfX3pGksul7Sso71t0rnTo/reyR6zXFK1/Cma+bqCC0a5bJrF++W6hZKUxDmX5lavWT1mtsHde4rLww7uSsyiShpWr+8tnn7pDi9lhst+X7Vjlgv4XZmbmErljCCDQxkWvOmgmoG/UZY+DDvzSSTnqkXH1nX6ZjG1+KWqctMwofpDVmFbs+WC/pyRu0OlZg7rwBoXpTgcufQuyv2VGfDUijNjrYuki1r8Mm6VpmFOb59SNTjXas1Wy5Wff6E5oKOdP+wZGcu+ORH5zwTUa0rseDXTmrySDgr8UlGlLoowLfJK3Sy1Fkgpfhirt3+Qz67aGLbKNSXRxaJFXqTRKPBLRZPpIy9uzY53RaycRfO6Qgf+jva2SV2UoqJFXqTRRBb4zewI4CbgELJTrG90968EefxXAd3A08B57v5iVPWQ8cnvapliVvahkc6OdnaP7K3ax5/fmp1o0B/7PJTtI4fszJ38YHrtvZtrDvom0cWitBLSSKJs8Y8An3P3R8xsf2CDmd1Hdq3ede6+wsyWAkuBL0RYDwmpuE+/XNBvb8sG8czwKG3BhaHSAGq5gH/7WVtKAmCt3EEXzp9VkLsk5yPzZ5Wd+VBr4FldLJJ2kQV+d98KbA1ev2JmjwNdwNnAScFuK4EHUOBvCJVy5rSZsdedzn3b2fnqCEOZ7IDpqDsd7W0s++BbCwK1u1ecl188uBomd1AuuFea11x84fjQ8V3c/8T2UFNNRdIolumcZtYNPAi8DXjG3TuDcgNezG0XfeYS4BKAWbNmHT8woMwQUas17XDBivVlu1HyH5QK8yBW/v5hvrOacg9HtbcZ++0zVcFeUq/SdM7IUzaY2Qzgh8Bn3f3l/Pc8e9Upe+Vx9xvdvcfde2bOnBl1NYXaqRUq9Z0/O5RhYGigJOjvs/dNZZ++zR9cnWzuoHJ3KcOjzlBmeCx5W6OlbxBJWqSB38zayQb977v76qD4eTM7NHj/UGBblHWQ8KolXOvtH6RSiqinOxbS/ZXugjJf5vR03Fh2//wLzGRzB4W5QNQjq6lIK4ks8AfdON8CHnf36/LeWgNcFLy+CLgjqjrI+FRLuHbtvZtLbs1enrq6JKna6vNWj83YCZO5M8w+1dTzAiGSFlHO6lkAfBR41MxyE7H/GlgB3GZmFwMDaN3ehlJp2mFxN0+lZRCLvwuqz1+f7Bz3cg9HlaOnZEVeo1w9UlNv/yCXrtqIA89MPwe3PQXvv7z0Zfaftn9sdSmXOyg/YdzOV0cY3vva/2tlwpS0Uq4embBcN0+ldW/jDPrlpn5efc6xBTOAtPi6SHUK/A2iODmZGQztCj8dMcpg97Pdp0JRT0lutk6cATVsemM9JStSnQJ/AyhuyeYekIJwGSWjWpgdqs/L74q53zyq5ShF0kaBvw4m29qu9MRsTqWMkrnjlptfP9kslLUexOpob+PkOTNZsGJ9bF0qSm8sUh9ac3eScq3twaHMhB8YCtNiLd4n/7iT+d5yKuXYyZ/m+aHju/jhhsFJ/d7Faq1LO9mpnyKSpRb/JNVjWb1KLdnifWodt9Zn8pW7S1m85vCS/fKTquX/PgtWrK/rcoJhuquU3likPhT4J6ke/c615qKXa9XW+v5yn8nvGspPdbxl6A9lg365pGq1jj84lKG3f3DcwVgDtyLxUeCfpHr0Oxe3ZHOzel7cNUybWUHKgdy+1e4SOoPPX7pqI9feu7nsOrm5oF9uimZ+X36lVny1409kYFkDtyLxUR//JNWr33nRvC5+uvQUnlpxJhuXfYBlH3wrHe1tYznxi/vQKx33I/NnsXtkLy/uKkxSduWaxwpa1MP2XEnQf93wuTWTquX/3u1TymfvqZQbp1of/mRz9ohIeAr8k1Qtv81kVOv6qHbc+5/YXvZz+VNEBzoW8uz0/1Gwz+zMWg4e/VjZupQLvovmdTFjeuUbxmqD0eUGgzVwKxIfdfXUQRT9zmG6Psod99Iq69O+0vYjduzzfwrKDn31q+zj3XS0t43N1Am7KPjQruGy5RBuMDq/G0kDtyLxUeBvUBMdO6j0uXJ9+d2ZtTjZu4VckO2ZfVDo4FvpWAahB6NrXchEpP5aNvA3e76WcjN9wnR9FH9ucNonGJmypWCf2Zleujr3Z8lZpedkPMG3XB2N7Bq5YQeD1YcvEr+WDPxRpjCIy0S7PvI/97Pdp5a8X5w6Oa46TvRCJiL115JpmSe7jms9JHnHUe7J23oG/Ilq9rswkWaTqrTMSc8JT/KOo1GDPqgPX6RRtGTgT7o/uR5pHMarkQO+iDSWlpzHn/Sc8LjvOCoF/VpJz0QknVqyxZ/0nPC47jiqtfJbYYBbRKLRkoEfku1PrucMlnIDoguPO4T2v28v2G+GvYV/+eB9Y9tJdDeFoQFekeS1bOBPUr3uOMq12hevORzWFO6Xy69z6aqN9A3s4KpFxyY+wF2O7kJEGoMCf0TqcceR32oftq08O/0vCt4/eM/n2W/0pLFtB77/0DP0zD4o8QHucirdhXzutk1cumqj7gBEYtKSg7utItc6zyZVKwz63Zm1BUE/x2EsFXOjJT2rdLcx6l63VbxEpDYF/gY2bf++khw7XZmVnDBtXdWW+7NDmciyhk5GmLuNSimdRaR+1NXToCotdp7far901UbKzdTPBdhGe2Cq1kpjOVp8RSRaCvx5GmHGyV+u/Uu+seEbBWXv3ucnbH3p1ZI69Q3s4PsPPVMQ/JPuzqmmeNB7itnYQjP5lLhNJFoK/IFGmHEy3qdvr1p07LjSKDeC/LuQ4nMOjX3hEmkVCvyBJOe9z/3GXDY9v6mgLGy6hUbrzhmPpB+0E0krBf5AUvPe055jp5kvXCLNSoE/EPe897QHfBFJjqZzBuKc914c9M895lwFfRGJjVr8gTj6m9XKF5FGoMCfJ6r+5pG9IyVJ1W750C2c/7bz634sEZFaFPgjpla+iDQaBf46yn8AbOYBu/mPPR8qeH/ePjfx4ksHsWDF+sSnLTbCw2oikgwF/jrJfxhpoGMhT+8pfH/OyN3syDRGOuJGeFhNRJJjXuaR+bp8sdm3gYXANnd/W1B2ELAK6AaeBs5z9xdrfVdPT4/39fVFUs9ivf2DXLnmMYYywwAcuG87yz741poBccGK9Tz10uNsnf5XBeXz97mbKbZP2amikE2elmttx9UKX7Bifdn6dHV28NOlp9T9eK1Ed0rSTMxsg7v3FJdH2eL/LvBV4Ka8sqXAOndfYWZLg+0vRFiHcentH2TJ/9vE8N7XLoYv7hpmyQ+yT9VW+wP/2e5TYXph2ezMWp7LjAKVHwLLtbb7Bnbwww2DsbTCG3GRlmagOyVpFZHN43f3B4EdRcVnAyuD1yuBRVEdfyKuvXdzQdDPGR71iqmC7/2ve0sGcGdl7hxbFeuwzo6aD4Flhke55eHfVUwZUW+V6qPkaNVVS+sh0kzifoDrEHffGrx+Djik0o5mdomZ9ZlZ3/bt22OpXLUWb7n3bLlx+vdPH9veb+87mZ1Zi5G9EOQeACv3cFixclkqa9VpohpxkZZmoDslaRWJPbnr2cGFigMM7n6ju/e4e8/MmTNjqVO1Fm/+e9f9/LqSVr4vc763aHXZhU/yF0WppM1Kp33WqtNENeIiLc1Ad0rSKuKe1fO8mR3q7lvN7FBgW8zHr2rJaUeX9PEDtLfZWGu4OOBfdfJV/M17/wao/gBY7r1KqYg/dHxXQR9/rjyqVriSo41fuYVkdKckzSjuwL8GuAhYEfy8I+bjV5ULhFes/k8yw3sBmGLw4T85gluevIzFa24r2H8iD2JVSw1RK7e+ZpQkS2mkpVVEOZ3zFuAk4GDgeWAZ0AvcBswCBshO5yweAC4R93TO4lZd8bq3d5x/B2cdfVYs9alWr472NnXRiEhFsU/ndPcLKrx1alTHrIf8mRu/m/4R9tpQwftJpVtIcqEYEWktSstc5NmhDE726dv8oH/Yq19LNMeOZpSISL0o8BcZnfFDnuk4u6BsdmYt3QfMSahGWZpRIiL1osAfGNk7Qtd1Xfxu9DtjZUdkbmN2Zm1DzNzQ3HsRqRcFfuCOJ+6g/e/befaVZwH4szmXc8K0dbSxb8PMcdfcexGpl1Rn58wMZ3jDl9/Azj07ATjlyFP4yUd/glV4mIIJWxgAAAXYSURBVCppmnsvIvWQ2sD/7f5vc/Gai8e2N358I8f90XEJ1khEJB6pC/xDrw5x4DUHjm1feOyFfO+c7yVYIxGReKUq8F/z79ewdN3Sse0nP/0kbzzwjQnWSEQkfqkI/Ftf2cph1x02tv35d3+eaz9wbYI1EhFJTssH/kvvuZQbHr5hbPu5zz3HITMqZoMWEWl5LT2d81N3fWos6H/5/V/Gl7mCvoikXku3+Bf+8UJ+uf2XrDl/DQdMPyDp6oiINISWDvxnHHUGZxx1RtLVEBFpKC3d1SMiIqUU+EVEUkaBX0QkZRT4RURSRoFfRCRlFPhFRFJGgV9EJGUU+EVEUsbck1tAPCwz2w4MJF2PGg4GXki6Eg1G56Q8nZfydF5KTfaczHb3mcWFTRH4m4GZ9bl7T9L1aCQ6J+XpvJSn81IqqnOirh4RkZRR4BcRSRkF/vq5MekKNCCdk/J0XsrTeSkVyTlRH7+ISMqoxS8ikjIK/CIiKaPAPwFm9m0z22Zmv8wrO8jM7jOz3wQ/D0yyjnEzsyPM7H4z+5WZPWZmnwnK035eppvZL8xsU3BelgflR5rZw2b2X2a2ysz2SbqucTOzNjPrN7O1wbbOidnTZvaomW00s76grO5/Qwr8E/Nd4PSisqXAOnc/ClgXbKfJCPA5dz8GmA98ysyOQedlN3CKux8HzAVON7P5wDXA9e7+ZuBF4OIE65iUzwCP523rnGSd7O5z8+bv1/1vSIF/Atz9QWBHUfHZwMrg9UpgUayVSpi7b3X3R4LXr5D9g+5C58XdfWew2R78c+AU4AdBeerOi5kdDpwJfDPYNlJ+Tqqo+9+QAn/9HOLuW4PXzwGHJFmZJJlZNzAPeBidl1yXxkZgG3Af8CQw5O4jwS5byF4k0+QG4HJgb7D9enROINso+LGZbTCzS4Kyuv8NtfRi60lxdzezVM6TNbMZwA+Bz7r7y9mGXFZaz4u7jwJzzawTuB2Yk3CVEmVmC4Ft7r7BzE5Kuj4N5kR3HzSzNwD3mdkT+W/W629ILf76ed7MDgUIfm5LuD6xM7N2skH/++6+OihO/XnJcfch4H7g3UCnmeUaXocDg4lVLH4LgLPM7GngVrJdPF8h3ecEAHcfDH5uI9tIeCcR/A0p8NfPGuCi4PVFwB0J1iV2QR/tt4DH3f26vLfSfl5mBi19zKwDeD/Z8Y/7gXOD3VJ1Xtz9Cnc/3N27gfOB9e5+ISk+JwBmtp+Z7Z97DXwA+CUR/A3pyd0JMLNbgJPIpkx9HlgG9AK3AbPIppA+z92LB4BblpmdCPwb8Civ9dv+Ndl+/jSfl7eTHZBrI9vQus3d/87M3ki2tXsQ0A98xN13J1fTZARdPZ9394VpPyfB7397sDkVuNnd/8HMXk+d/4YU+EVEUkZdPSIiKaPALyKSMgr8IiIpo8AvIpIyCvwiIimjwC8yDmZ2kpmdMMnv2Fl7L5HoKPCLjM9JwKQCv0jSFPhFADPrDRJjPZZLjmVmp5vZI0Eu/XVB8rlPAJcG+dLfY2bfNbNz875nZ/BzRvCZR4L86mcn8XuJlKMHuETILnbh7juCtAr/AZwK9AHvdfen8t6/Etjp7l8OPvddYK27/yDY3unuM4KcM/sGieoOBh4CjgqSbO109xkJ/JoigLJziuR82swWB6+PAC4BHnT3pwAm8Ii8Af9oZu8lm8Kii2w63efqVF+RCVPgl9QL8sX8KfBud99lZg8AGwmXPnmEoMvUzKYAueUCLwRmAse7+3CQiXJ6fWsuMjHq4xeBA4AXg6A/h+zSkdOB95rZkZDtCgr2fQXYP++zTwPHB6/PIrvCVu47twVB/2RgdrS/gkh46uOX1DOzaWSzq3YDm4FO4EqgA/hHsg2kbe7+fjP7Y7LLA+4F/ifwa7JpcjuAe4BPBX38BwN3AjPIjhXMB85w96fVxy9JU+AXEUkZdfWIiKSMAr+ISMoo8IuIpIwCv4hIyijwi4ikjAK/iEjKKPCLiKTM/wexpTMORXJsDwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtTdwSdrm6rZ"
      },
      "source": [
        "#Forest of Extremely randomized trees\n",
        "We now implement an extremely randomized forest as an ensemble of Extra-trees. The rationale behind this approach is that the increased explicit randomization of the attributes and cut-points, when combined with ensemble averaging should be able to reduce variance more strongly than the previously implemented weaker randomization technique. The **results from each extra-tree is averaged** to give the final result.\n",
        "\n",
        "We avoid using bootstrap replicas and intsead go for the full original training sample to minimize the bias. Computationally this implementation is much more efficient than the previous as we no longer need to iterate over all features and explicitly calculate the cut-split value for them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrfUQZX0nm5H"
      },
      "source": [
        "from numpy.random import choice, seed\n",
        "\n",
        "class RandomForest:\n",
        "\n",
        "    trees = []\n",
        "    importance = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y, num_trees = 1, frac_samples = None, frac_attrs = None, bootstrap=False, extremely_randomized=False, subset_size_factor=1/np.sqrt(len(X_train[0]))):\n",
        "        seed(0)\n",
        "        if extremely_randomized and bootstrap:\n",
        "          print('----------------Extremely randomized tress run without bootstrap------------------')\n",
        "          bootstrap = False\n",
        "        N, total_attributes = X.shape \n",
        "        self.importance = np.zeros(total_attributes)\n",
        "\n",
        "        if frac_samples == None:\n",
        "            frac_samples = 1.0\n",
        "\n",
        "        if frac_attrs == None:\n",
        "            frac_attrs = 1.0\n",
        "\n",
        "        for i in range(num_trees):\n",
        "            new_tree = DecisionTree()\n",
        "            sample = choice(range(N), size = int(N * frac_samples), replace=bootstrap)\n",
        "            attrs = choice(range(total_attributes), size = int(total_attributes * frac_attrs), replace=bootstrap)\n",
        "            #print(attrs, end=\", \")\n",
        "            dataset = X[sample, :]   #[:, attrs]\n",
        "            ys = y[sample]\n",
        "            new_tree.fit(dataset, ys, min_coef_of_var = 0.025, pruning_factor = 0, extremely_randomized=extremely_randomized, subset_size_factor=subset_size_factor)\n",
        "\n",
        "            self.importance += new_tree.get_reductions()\n",
        "\n",
        "            self.trees.append((new_tree, attrs))\n",
        "\n",
        "        self.importance /= num_trees\n",
        "\n",
        "    def predict(self, X):\n",
        "        \n",
        "        N, _ = X.shape \n",
        "\n",
        "        answer = np.zeros(N)\n",
        "\n",
        "        for (t, attrs) in self.trees:\n",
        "            answer += t.predict(X) # [:, attrs])\n",
        "        \n",
        "        return answer / len(self.trees)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiZjRa6Htj0k"
      },
      "source": [
        "rf = RandomForest()\n",
        "rf.fit(X_train, y_train, num_trees = 100, frac_samples = 1, frac_attrs = 1.0, bootstrap=False, extremely_randomized=True, subset_size_factor=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz4sagAe7g69"
      },
      "source": [
        "And then we test it on our test-data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thF_c4Uetrsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41abbaec-62d2-4098-db52-5aa215a2701a"
      },
      "source": [
        "y_test_rf = rf.predict(X_test)\n",
        "y_test_rf\n",
        "metrics.r2_score(y_test, y_test_rf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8792682371177334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvMNQZzf7l6-"
      },
      "source": [
        "We also calculate the results using sklearn's RandomForestRegressor for comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o_jN3MpuEc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc633cc-921e-4d14-820f-f3959610d6c1"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rfsk = RandomForestRegressor(bootstrap=True)\n",
        "rfsk.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YADeDtpRwzKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78414c7b-7a9a-4690-968b-35490e6a785d"
      },
      "source": [
        "y_test_rfsk = rfsk.predict(X_test)\n",
        "metrics.r2_score(y_test, y_test_rfsk)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.905033102965088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2-61CTh76uO"
      },
      "source": [
        "We see that scikit-learn manages an accuracy of ~90%. Our ~88% is quite comparable, given that our implementation is very bare-bones, and mostly proof-of-concept.\n",
        "\n",
        "Finally, we plot our predictions as opposed to the ground truth (x = y). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ42jxDD3dLR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "f65d9ea2-a532-49c1-dcb5-7aee5be643d4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(y_test, y_test, color = \"green\")\n",
        "plt.xlabel(\"actual\")\n",
        "plt.ylabel(\"predicted\")\n",
        "plt.scatter(y_test, y_test_rf)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFzloE7U8W4J"
      },
      "source": [
        "We see that a large chunk of the predicted points is really close to the ground truths. This is because of the averaging step in the Random Forests, and contributes immensely to the accuracy.\n",
        "\n",
        "## Variable Importance\n",
        "\n",
        "Now we take a look at the importance of variables. For this purpose, we compute the following quantity for each tree $T$ in the ensemble:\n",
        "\n",
        "$\\mathrm{VarReduction}_i = \\sum_{x \\in T} \\mathrm{Optimal\\ Variance\\ Reduction\\ in\\ node\\ } x \\mathrm{\\ by\\ attribute\\ } i$\n",
        "\n",
        "and then denote \n",
        "\n",
        "$\\mathrm{Importance}_i = \\mathrm{Average\\ of\\ VarReduction}_i$\n",
        "\n",
        "This quantity will be the importance of attribute $i$. We plot these quantities in a relative sense.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxnUDubGHjQx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "e2056345-5247-4886-d551-96c6611153d0"
      },
      "source": [
        "importance = rf.importance\n",
        "relative_importance = importance / np.sum(importance)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(data.feature_names, relative_importance)\n",
        "plt.ylabel('Relative Importance')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKCn5GQgQ_3b"
      },
      "source": [
        "The following are the meanings of the attributes:\n",
        "\n",
        "    CRIM - per capita crime rate by town\n",
        "    ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "    INDUS - proportion of non-retail business acres per town.\n",
        "    CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
        "    NOX - nitric oxides concentration (parts per 10 million)\n",
        "    RM - average number of rooms per dwelling\n",
        "    AGE - proportion of owner-occupied units built prior to 1940\n",
        "    DIS - weighted distances to five Boston employment centres\n",
        "    RAD - index of accessibility to radial highways\n",
        "    TAX - full-value property-tax rate per $10,000\n",
        "    PTRATIO - pupil-teacher ratio by town\n",
        "    B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "    LSTAT - % lower status of the population\n",
        "    MEDV - Median value of owner-occupied homes in $1000's\n",
        "\n",
        "\n",
        "So we can see that the most important attribute is RM, which is the average number of rooms. This makes sense, because the number of rooms is an important factor. The 2nd most important factor is LSTAT, which is the percentage of the population which is of lower status. This can be interpreted to mean that the price is lower in underdeveloped regions. And the 3rd most important factor is crime rate (CRIM), which too makes a lot of sense. On the other end, the CHAS variable is about the Charles River. It doesn't make too much of an impact on the price."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSdyf2pqbi3V"
      },
      "source": [
        "#Results comparison with alternative approaches\n",
        "Finally we run different instances of our model wit slightly differences to compare the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVEa-CYwdMSN"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq5to6-Ab-yT"
      },
      "source": [
        "##Implementation in Project 1: Without extra-trees\n",
        "We use the bootstrapping technique while training to generate randomized trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PgMAamUQKn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "532957e3-0ce1-443e-9489-dcef54422358"
      },
      "source": [
        "start_time = time.time()\n",
        "rf = RandomForest()\n",
        "rf.fit(X_train, y_train, num_trees = 100, frac_samples = 1, frac_attrs = 1.0, bootstrap=True, extremely_randomized=False, subset_size_factor=0.45)\n",
        "y_test_rf = rf.predict(X_test)\n",
        "y_test_rf\n",
        "print('R2 Score: ', metrics.r2_score(y_test, y_test_rf))\n",
        "print('Time taken to run: ', time.time()-start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 Score:  0.8576024032476958\n",
            "Time taken to run:  145.09849524497986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK2bgfVYcRZE"
      },
      "source": [
        "We use the implementation in project 1 with bootstrapping combined with taking a fraction of features to grow more randomized individual tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0zW3f04e6Ms",
        "outputId": "bf2c7d0f-1e98-40de-abdf-705f3535d44b"
      },
      "source": [
        "start_time = time.time()\n",
        "rf = RandomForest()\n",
        "rf.fit(X_train, y_train, num_trees = 100, frac_samples = 1, frac_attrs = 0.7, bootstrap=True, extremely_randomized=False, subset_size_factor=0.45)\n",
        "y_test_rf = rf.predict(X_test)\n",
        "y_test_rf\n",
        "print('R2 Score: ', metrics.r2_score(y_test, y_test_rf))\n",
        "print('Time taken to run: ', time.time()-start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 Score:  0.8656771069680278\n",
            "Time taken to run:  138.87495183944702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D76ExX9ujT6e",
        "outputId": "63107e2a-85f4-4fe2-a321-f86161e54cbf"
      },
      "source": [
        "start_time = time.time()\n",
        "rf = RandomForest()\n",
        "rf.fit(X_train, y_train, num_trees = 50, frac_samples = 1, frac_attrs = 0.7, bootstrap=True, extremely_randomized=False, subset_size_factor=0.45)\n",
        "y_test_rf = rf.predict(X_test)\n",
        "y_test_rf\n",
        "print('R2 Score: ', metrics.r2_score(y_test, y_test_rf))\n",
        "print('Time taken to run: ', time.time()-start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 Score:  0.8710594342964576\n",
            "Time taken to run:  71.20021986961365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfe4ZU6sewxl"
      },
      "source": [
        "##New implementation: Using Extremely randomized/Extra trees\n",
        "We run the model multiple times with different set parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjejqWqRb4f5",
        "outputId": "030fa636-1e57-4715-adf9-5cf1366a8965"
      },
      "source": [
        "start_time = time.time()\n",
        "rf = RandomForest()\n",
        "rf.fit(X_train, y_train, num_trees = 100, frac_samples = 1, frac_attrs = 1.0, bootstrap=False, extremely_randomized=True, subset_size_factor=0.45)\n",
        "y_test_rf = rf.predict(X_test)\n",
        "y_test_rf\n",
        "print('R2 Score: ', metrics.r2_score(y_test, y_test_rf))\n",
        "print('Time taken to run: ', time.time()-start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 Score:  0.867215782842968\n",
            "Time taken to run:  109.24748802185059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC97COcCf9gH",
        "outputId": "7cdcda93-e506-41bf-bc0a-3f1d1cdd51e1"
      },
      "source": [
        "start_time = time.time()\n",
        "rf = RandomForest()\n",
        "rf.fit(X_train, y_train, num_trees = 100, frac_samples = 1, frac_attrs = 1.0, bootstrap=False, extremely_randomized=True, subset_size_factor=0.3)\n",
        "y_test_rf = rf.predict(X_test)\n",
        "y_test_rf\n",
        "print('R2 Score: ', metrics.r2_score(y_test, y_test_rf))\n",
        "print('Time taken to run: ', time.time()-start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 Score:  0.8344705204000646\n",
            "Time taken to run:  100.29421710968018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNRNuoZ1hKnB",
        "outputId": "1d42c96e-e4a7-4308-dee6-8517201857b7"
      },
      "source": [
        "start_time = time.time()\n",
        "rf = RandomForest()\n",
        "rf.fit(X_train, y_train, num_trees = 100, frac_samples = 1, frac_attrs = 1.0, bootstrap=False, extremely_randomized=True, subset_size_factor=0.7)\n",
        "y_test_rf = rf.predict(X_test)\n",
        "y_test_rf\n",
        "print('R2 Score: ', metrics.r2_score(y_test, y_test_rf))\n",
        "print('Time taken to run: ', time.time()-start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 Score:  0.8844838534245865\n",
            "Time taken to run:  118.73557686805725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7VBj_oxhpw7",
        "outputId": "69d1fac1-2388-4a87-d4a9-54651fae03b5"
      },
      "source": [
        "start_time = time.time()\n",
        "rf = RandomForest()\n",
        "rf.fit(X_train, y_train, num_trees = 50, frac_samples = 1, frac_attrs = 1.0, bootstrap=False, extremely_randomized=True, subset_size_factor=0.7)\n",
        "y_test_rf = rf.predict(X_test)\n",
        "y_test_rf\n",
        "print('R2 Score: ', metrics.r2_score(y_test, y_test_rf))\n",
        "print('Time taken to run: ', time.time()-start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 Score:  0.8897696687443407\n",
            "Time taken to run:  60.10095024108887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqTYacYwkFhv"
      },
      "source": [
        "#Conclusion\n",
        "We make the following observations from above experiments:\n",
        "\n",
        "\n",
        "*   Using extremely-randomized trees gives an **increase of about $2\\%$** as compared to the classical radom forests. \n",
        "*   The Extremely randomized approach is **computationally much more efficient**.\n",
        "*   We observe that there is a significant difference in the computational efficiency even for the small dataset that we have used. For a dataset with larger number of training samples and attribute space this difference will increase further. \n",
        "*   The ensemble method performance is optimized even with upto just 50 trees.\n",
        "\n",
        "*   Our Extremely randomized model with the parameters achived a $R2score$ of $~89\\%$ which comes very close to the $90\\%$ score optimized random forest implementation of *sci-kit learn*.\n",
        "\n",
        "#References:\n",
        "\n",
        "\n",
        "*   https://towardsdatascience.com/an-intuitive-explanation-of-random-forest-and-extra-trees-classifiers-8507ac21d54b\n",
        "*   Extremely randomized trees: https://link.springer.com/article/10.1007/s10994-006-6226-1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}